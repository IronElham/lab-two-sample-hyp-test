{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources (README.md file)\n",
    "- Happy learning!\n",
    "\n",
    "- **Consider a significance level of 5% for all tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import scipy.stats as st \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Independent Sample T-tests\n",
    "\n",
    "In this challenge, we will be using the Pokemon dataset. Before applying statistical methods to this data, let's first examine the data.\n",
    "\n",
    "To load the data, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon = pd.read_csv(r'C:\\Users\\elham\\OneDrive\\Documents\\IRONHACK\\lab\\EDA\\pokemon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by looking at the `head` function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>name</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>total</th>\n",
       "      <th>hp</th>\n",
       "      <th>attack</th>\n",
       "      <th>defense</th>\n",
       "      <th>sp._atk</th>\n",
       "      <th>sp._def</th>\n",
       "      <th>speed</th>\n",
       "      <th>generation</th>\n",
       "      <th>legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   name type_1  type_2  total  hp  attack  defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   sp._atk  sp._def  speed  generation  legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pokemon.copy()\n",
    "df.columns = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we would like to do is compare the legendary Pokemon to the regular Pokemon. To do this, we should examine the data further. What is the count of legendary vs. non legendary Pokemons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "legendary\n",
       "False    735\n",
       "True      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 735 Pokemon are non-legendary, while 65 are legendary\n",
    "df['legendary'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean and standard deviation of the total points for both legendary and non-legendary Pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = df[df['legendary'] == True]\n",
    "non_legend = df[df['legendary'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['legendary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27338958434995064"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['legendary'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#             470.215385\n",
       "total         637.384615\n",
       "hp             92.738462\n",
       "attack        116.676923\n",
       "defense        99.661538\n",
       "sp._atk       122.184615\n",
       "sp._def       105.938462\n",
       "speed         100.184615\n",
       "generation      3.769231\n",
       "legendary       1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_legend = df[df['legendary'] == True].mean(numeric_only=True)\n",
    "mean_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#             353.315646\n",
       "total         417.213605\n",
       "hp             67.182313\n",
       "attack         75.669388\n",
       "defense        71.559184\n",
       "sp._atk        68.454422\n",
       "sp._def        68.892517\n",
       "speed          65.455782\n",
       "generation      3.284354\n",
       "legendary       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_non_legend = df[df['legendary'] == False].mean(numeric_only=True)\n",
    "mean_non_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#              int64\n",
       "name          object\n",
       "type_1        object\n",
       "type_2        object\n",
       "total          int64\n",
       "hp             int64\n",
       "attack         int64\n",
       "defense        int64\n",
       "sp._atk        int64\n",
       "sp._def        int64\n",
       "speed          int64\n",
       "generation     int64\n",
       "legendary       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation of the mean might give us a clue regarding how the statistical test may turn out; However, it certainly does not prove whether there is a significant difference between the two groups.\n",
    "\n",
    "In the cell below, use the `ttest_ind` function in `scipy.stats` to compare the the total points for legendary and non-legendary Pokemon. Since we do not have any information about the population, assume the variances are not equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothsis: The means of total points legendary and non_legendary Pokemon are equal.\n",
    "Alternative hypothesis: the means of total points for legendary and non_legendary are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (t): 25.83\n",
      "P-Value: 0.000000000000000000000000000000000000000000000093579543359574\n",
      "\n",
      "Reject the Null Hypothesis: There is sufficient evidence to conclude that the mean of total points are different for legends and non_legends.\n"
     ]
    }
   ],
   "source": [
    "legend = df[df['legendary'] == True]['total']\n",
    "non_legend = df[df['legendary'] == False]['total']\n",
    "\n",
    "#two-sample t-test for independent samples\n",
    "t_stat, p_value = st.ttest_ind(legend, non_legend, equal_var=False) \n",
    "print(f\"Test Statistic (t): {t_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.60f}\")\n",
    "print()\n",
    "\n",
    "# Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision-Making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The mean total points for legend and non_legend are not significantly different.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is sufficient evidence to conclude that the mean of total points are different for legends and non_legends.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you conclude from this test? Write your conclusions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion\n",
    "On average, legenedry and non_legendry pokemon scored differently as mean of total points are different for legends and non_legends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about we try to compare the different types of pokemon? In the cell below, list the types of Pokemon from column `Type 1` and the count of each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_1\n",
       "Water       112\n",
       "Normal       98\n",
       "Grass        70\n",
       "Bug          69\n",
       "Psychic      57\n",
       "Fire         52\n",
       "Electric     44\n",
       "Rock         44\n",
       "Dragon       32\n",
       "Ground       32\n",
       "Ghost        32\n",
       "Dark         31\n",
       "Poison       28\n",
       "Steel        27\n",
       "Fighting     27\n",
       "Ice          24\n",
       "Fairy        17\n",
       "Flying        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_1_pokeman = df['type_1'].value_counts()\n",
    "type_1_pokeman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothsis: The proportion of Pokeman types are equal.\n",
    "* Alternative hypothesis: the proportion of Pokemon types are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_pvalue: 1.0000000000\n"
     ]
    }
   ],
   "source": [
    "#create contingency table to see the frequencies \n",
    "contingency_tab = pd.crosstab(index=df['type_1'], columns='count')\n",
    "chi2_stats, chi2_pvalue, dof, expected = chi2_contingency(contingency_tab)\n",
    "print(f\"chi2_pvalue: {chi2_pvalue:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 297.7750\n",
      "P-value: 0.0000000000000000000000000000000000000000\n",
      "Reject the Null Hypothesis: There is a significant difference in the proportions of Pokemon types.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "#use another test chi-squared goodness of fit\n",
    "# Chi-square test for comparison of categorical varaibles\n",
    "pokeman_1= type_1_pokeman.values\n",
    "\n",
    "# expected frequencies \n",
    "total_count = pokeman_1.sum()\n",
    "expected_count = [total_count / len(pokeman_1)] * len(pokeman_1)\n",
    "\n",
    "# chi-square goodness of fit better for comparisionb of frequencies\n",
    "chi2_stats, chi2_pvalue = chisquare(f_obs=pokeman_1, f_exp=expected_count)\n",
    "\n",
    "print(f\"Chi-square Statistic: {chi2_stats:.4f}\")\n",
    "print(f\"P-value: {chi2_pvalue:.40f}\")\n",
    "\n",
    "# Decision making\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The proportions of Pokemon types are not significantly different.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is a significant difference in the proportions of Pokemon types.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 4.6388\n",
      "P-Value: 0.0000000021\n",
      "\n",
      "Reject the Null Hypothesis: The means of total points significantly differ among Pokémon types.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# extract unique values in type_1\n",
    "unique_types = df['type_1'].unique()\n",
    "\n",
    "# create dictionary to store data for each type\n",
    "type_data = {type_: df[df['type_1'] == type_]['total'] for type_ in unique_types}\n",
    "\n",
    "# ANOVA test\n",
    "anova_result = f_oneway(*type_data.values())\n",
    "\n",
    "print(f\"F-Statistic: {anova_result.statistic:.4f}\")\n",
    "print(f\"P-Value: {anova_result.pvalue:.10f}\")\n",
    "print()\n",
    "\n",
    "# Decision making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The means of total points do not significantly differ among Pokémon types.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: The means of total points significantly differ among Pokémon types.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since water is the largest group of Pokemon, compare the mean and standard deviation of water Pokemon to all other Pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Water Pokemon -> Mean : 449.06, Std Dev : 109.27\n",
      "Non_water Pokemon -> Mean : 457.74, Std Dev : 122.56\n"
     ]
    }
   ],
   "source": [
    "# creating two groups of water and non water \n",
    "water_pokemon = df[df['type_1'] == 'Water'].dropna()\n",
    "non_water_pokemon = df[df['type_1'] != 'Water'].dropna()\n",
    "\n",
    "# Calculate mean and standard deviation for the 'total' column\n",
    "water_mean = water_pokemon['total'].mean()\n",
    "water_std = water_pokemon['total'].std()\n",
    "\n",
    "non_water_pokemon_mean = non_water_pokemon['total'].mean()\n",
    "non_water_pokemon_std = non_water_pokemon['total'].std()\n",
    "\n",
    "\n",
    "print(f\"Water Pokemon -> Mean : {water_mean:.2f}, Std Dev : {water_std:.2f}\")\n",
    "print(f\"Non_water Pokemon -> Mean : {non_water_pokemon_mean:.2f}, Std Dev : {non_water_pokemon_std:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a hypothesis test comparing the mean of total points for water Pokemon to all non-water Pokemon. Assume the variances are equal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothsis: The means of total points for Water and non-Water Pokemon are equal.\n",
    "* Alternative hypothesis: the means of total points for Water and non-Water Pokemon are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (t): -0.44\n",
      "P-Value: 0.658714\n",
      "Fail to Reject the Null Hypothesis: The means of total points for Water and non-Water Pokemon are not significantly different.\n"
     ]
    }
   ],
   "source": [
    "# creating two groups of water and non water pokeman\n",
    "water_pokemon = df[df['type_1'] == 'Water']['total'].dropna()\n",
    "non_water_pokemon = df[df['type_1'] != 'Water']['total'].dropna()\n",
    "\n",
    "# two smaple t-test assuming equal variances\n",
    "t_stat, p_value = st.ttest_ind(water_pokemon, non_water_pokemon, equal_var=True)\n",
    "\n",
    "print(f\"Test Statistic (t): {t_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.6f}\")\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision-Making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The means of total points for Water and non-Water Pokemon are not significantly different.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is sufficient evidence to conclude that the means of total points for Water and non-Water Pokemon are significantly different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your conclusion below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of two groups water and other pokeman are not significantly different. Both groups have similar total performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Matched Pairs Test\n",
    "\n",
    "In this challenge we will compare dependent samples of data describing our Pokemon. Our goal is to see whether there is a significant difference between each Pokemon's defense and attack scores. Our hypothesis is that the defense and attack scores are equal. In the cell below, import the `ttest_rel` function from `scipy.stats` and compare the two columns to see if there is a statistically significant difference between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: The mean of defense and attack scores are equal.\n",
    "\n",
    "Alternative hypothesis: There is a significant difference between mean of defense and attack scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (t): -4.33\n",
      "P-Value: 0.000017\n",
      "\n",
      "Reject the Null Hypothesis: There is a significant difference between mean of defense and attack scores.\n"
     ]
    }
   ],
   "source": [
    "# paired ttest to compare attack and defence scores\n",
    "t_stat, p_value = ttest_rel(df['defense'], df['attack'])\n",
    "\n",
    "print(f\"Test Statistic (t): {t_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.6f}\")\n",
    "print()\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision-making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The mean of defense and attack scores are not significantly different.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is a significant difference between mean of defense and attack scores.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the results of the test in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conclusions:\n",
    "There is a significant difference between mean of defense and attack scores of each pokeman.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also curious about whether therer is a significant difference between the mean of special defense and the mean of special attack. Perform the hypothesis test in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: The mean of special defense and special attack scores are equal.\n",
    "Alternative hypothesis: There is a significant difference between mean of special defense and special attack scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (t): 0.85\n",
      "P-Value: 0.393369\n",
      "\n",
      "Fail to Reject the Null Hypothesis: The mean of special defense and spacial attack scores are not significantly different.\n"
     ]
    }
   ],
   "source": [
    "# paired ttest to compare attack and defence scores\n",
    "t_stat, p_value = ttest_rel(df['sp._atk'], df['sp._def'])\n",
    "\n",
    "print(f\"Test Statistic (t): {t_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.6f}\")\n",
    "print()\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision-making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The mean of special defense and spacial attack scores are not significantly different.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is a significant difference between mean of special defense and special attack scores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the results of the test in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusions:\n",
    "Contrary to the normal attack and defense, the mean of special attack and defense is similar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may recall, a two sample matched pairs test can also be expressed as a one sample test of the difference between the two dependent columns.\n",
    "\n",
    "Import the `ttest_1samp` function and perform a one sample t-test of the difference between defense and attack. Test the hypothesis that the difference between the means is zero. Confirm that the results of the test are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (t): -4.33\n",
      "P-Value: 0.000017\n",
      "\n",
      "Reject the Null Hypothesis: The difference between defense and attack means is significantly different from zero.\n"
     ]
    }
   ],
   "source": [
    "# difference between 'defense' and 'attack'\n",
    "difference = df['defense'] - df['attack']\n",
    "\n",
    "# one-sample t-test on the difference\n",
    "t_stat, p_value = ttest_1samp(difference, 0)\n",
    "\n",
    "\n",
    "print(f\"Test Statistic (t): {t_stat:.2f}\")\n",
    "print(f\"P-Value: {p_value:.6f}\")\n",
    "print()\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Decision-making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: The difference between defense and attack means is not significantly different from zero.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: The difference between defense and attack means is significantly different from zero.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - The Chi-Square Test\n",
    "\n",
    "The Chi-Square test is used to determine whether there is a statistically significant difference in frequencies. In other words, we are testing whether there is a relationship between categorical variables or rather when the variables are independent. This test is an alternative to Fisher's exact test and is used in scenarios where sample sizes are larger. However, with a large enough sample size, both tests produce similar results. Read more about the Chi Squared test [here](https://en.wikipedia.org/wiki/Chi-squared_test).\n",
    "\n",
    "In the cell below, create a contingency table using `pd.crosstab` comparing whether a Pokemon is legenadary or not and whether the Type 1 of a Pokemon is water or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>legendary</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_water</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>627</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "legendary  False  True \n",
       "is_water               \n",
       "False        627     61\n",
       "True         108      4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating new column to check whether type_1 is Water or not\n",
    "df['is_water'] = df['type_1'] == 'Water'\n",
    "\n",
    "# contingency table\n",
    "contingency_table = pd.crosstab(df['is_water'], df['legendary'])\n",
    "contingency_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a chi-squared test using the `chi2_contingency` function in `scipy.stats`. You can read the documentation of the function [here](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.chi2_contingency.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi2_pvalue: 0.0862546725\n"
     ]
    }
   ],
   "source": [
    "# Chi-Square test\n",
    "chi2_stats, chi2_pvalue, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"chi2_pvalue: {chi2_pvalue:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a 95% confidence, should we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the Null Hypothesis: There is association or relationship between whether a Pokemon is legendary and whether its Type 1 is Water.\n"
     ]
    }
   ],
   "source": [
    "# p value from chi squared result is less than alpha 0.05 \n",
    "# Decision-making\n",
    "if p_value > alpha:\n",
    "    print(\"Fail to Reject the Null Hypothesis: There is no relationship between whether a Pokemon is legendary and whether its Type 1 is Water.\")\n",
    "else:\n",
    "    print(\"Reject the Null Hypothesis: There is association or relationship between whether a Pokemon is legendary and whether its Type 1 is Water.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06724447151934329"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the strength of p value with cremer's v\n",
    "from scipy.stats.contingency import association\n",
    "association(contingency_table, method='cramer')\n",
    "#0.06 is a moderate to stong assoication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
